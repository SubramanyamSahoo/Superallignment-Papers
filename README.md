# Superallignment-Papers

## The goal is to build safe AI which must be implicitly responsible 


## Here I will markdown all papers related to superallignment 
